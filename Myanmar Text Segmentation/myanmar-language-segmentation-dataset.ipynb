{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":31234,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from datasets import Dataset, DatasetDict, Features, Sequence, ClassLabel, Value, load_dataset\nfrom itertools import chain\nimport fasttext\nfrom huggingface_hub import hf_hub_download\nimport re\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom huggingface_hub import login\n\nlogin(token=\"\")","metadata":{"execution":{"iopub.status.busy":"2025-12-23T16:01:40.407538Z","iopub.execute_input":"2025-12-23T16:01:40.407809Z","iopub.status.idle":"2025-12-23T16:01:53.646268Z","shell.execute_reply.started":"2025-12-23T16:01:40.407781Z","shell.execute_reply":"2025-12-23T16:01:53.645391Z"},"trusted":true},"outputs":[],"execution_count":1},{"cell_type":"markdown","source":"# Load Dataset and Language Classifcation Model","metadata":{}},{"cell_type":"code","source":"ds = load_dataset(\"chuuhtetnaing/myanmar-wikipedia-dataset\")\n\nmodel_path = hf_hub_download(repo_id=\"facebook/fasttext-language-identification\", filename=\"model.bin\")\nmodel = fasttext.load_model(model_path)","metadata":{"execution":{"iopub.status.busy":"2025-12-23T16:01:56.556245Z","iopub.execute_input":"2025-12-23T16:01:56.556591Z","iopub.status.idle":"2025-12-23T16:02:21.898486Z","shell.execute_reply.started":"2025-12-23T16:01:56.556559Z","shell.execute_reply":"2025-12-23T16:02:21.897603Z"},"trusted":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"README.md: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9824cf92372b46bda08b74ee7a0e8476"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"data/train-00000-of-00003.parquet:   0%|          | 0.00/92.1M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b7af56cb0758491e87d212244baccf43"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"data/train-00001-of-00003.parquet:   0%|          | 0.00/106M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3f7f3d68c5b747719c816a7eb4f4956e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"data/train-00002-of-00003.parquet:   0%|          | 0.00/117M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"be06c310d06a42babd24598539692402"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/116340 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"01f4f7505ea74c5b9374152c8a690f0a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.bin:   0%|          | 0.00/1.18G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f5251339860f457fbe5894ce977dc643"}},"metadata":{}}],"execution_count":2},{"cell_type":"code","source":"model.predict([\"Hello, world!\"])[0][0][0]","metadata":{"execution":{"iopub.status.busy":"2025-12-23T16:02:21.900154Z","iopub.execute_input":"2025-12-23T16:02:21.900508Z","iopub.status.idle":"2025-12-23T16:02:21.906539Z","shell.execute_reply.started":"2025-12-23T16:02:21.900475Z","shell.execute_reply":"2025-12-23T16:02:21.905714Z"},"trusted":true},"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"'__label__eng_Latn'"},"metadata":{}}],"execution_count":3},{"cell_type":"markdown","source":"# Preprocess Functions","metadata":{}},{"cell_type":"code","source":"import re\n\ndef create_break_pattern():\n    \"\"\"Creates pattern for Myanmar syllable breaking.\"\"\"\n    my_consonant = r\"က-အ\"\n    other_char = r\"ဣဤဥဦဧဩဪဿ၌၍၏၀-၉၊။\"\n    symbols = r\"!\\\"#$%&'()*+,\\-./:;<=>?@\\[\\\\\\]^_`{|}~\"\n    subscript_symbol = r'္'\n    a_that = r'်'\n    \n    return re.compile(\n        r\"((?<!\" + subscript_symbol + r\")[\" + my_consonant + r\"]\"\n        r\"(?![\" + a_that + subscript_symbol + r\"])\"\n        + r\"|[\" + other_char + r\"]\"\n        + r\"|[\" + symbols + r\"])\"\n    )\n\nbreak_pattern = create_break_pattern()\n\ndef break_syllables_myanmar(text, separator=\"|X|\"):\n    \"\"\"Apply Myanmar syllable breaking.\"\"\"\n    segmented = break_pattern.sub(separator + r\"\\1\", text)\n    if segmented.startswith(separator):\n        segmented = segmented[len(separator):]\n    return [s for s in segmented.split(separator) if s]\n\ndef is_myanmar(text):\n    \"\"\"Check if text contains Myanmar characters.\"\"\"\n    return bool(re.search(r'[\\u1000-\\u109F]', text))\n\ndef tokenize_chunk(chunk):\n    \"\"\"\n    Tokenize a single chunk (no spaces).\n    - If contains Myanmar: split by script, syllable-break Myanmar parts\n    - If no Myanmar: keep as single token\n    \"\"\"\n    if not chunk:\n        return []\n    \n    # If no Myanmar, keep entire chunk as single token\n    if not is_myanmar(chunk):\n        return [chunk]\n    \n    # If has Myanmar, split by script boundaries\n    tokens = []\n    \n    # Pattern: Myanmar block OR non-Myanmar block\n    pattern = re.compile(\n        r'([\\u1000-\\u109F]+)'      # Myanmar characters\n        r'|([^\\u1000-\\u109F]+)'    # Non-Myanmar characters\n    )\n    \n    for match in pattern.finditer(chunk):\n        myanmar, non_myanmar = match.groups()\n        \n        if myanmar:\n            # Myanmar: split into syllables\n            syllables = break_syllables_myanmar(myanmar)\n            tokens.extend(syllables)\n        elif non_myanmar:\n            # Non-Myanmar: keep as single token\n            tokens.append(non_myanmar)\n    \n    return tokens\n\ndef is_english(char):\n    return bool(re.match(r'[a-zA-Z]', char))\n\ndef create_labels(line):\n    \"\"\"\n    Create tokens and B/I labels from word-segmented text.\n    \n    1. Split by spaces (trust ground truth word boundaries)\n    2. For each chunk: detect Myanmar and tokenize accordingly\n    \"\"\"\n    segments = line.split()  # Trust spaces as word boundaries\n    \n    line_tokens = []\n    line_labels = []\n    \n    for segment in segments:\n        tokens = tokenize_chunk(segment)\n        \n        if tokens:\n            # First token is 'B', rest are 'I'\n            segment_labels = ['I'] * len(tokens)\n            segment_labels[0] = 'B'\n\n            if line_tokens:\n                if is_english(tokens[0][0]) and is_english(line_tokens[-1][-1]):\n                    tokens[0] = \" \"+tokens[0]\n            \n            line_tokens.extend(tokens)\n            line_labels.extend(segment_labels)\n    \n    return {\"tokens\": line_tokens, \"labels\": line_labels}\n\n\ndef reconstruct(tokens, labels):\n    result = []\n    for token, label in zip(tokens, labels):\n        if label == \"B\" and result:\n            result.append(\" \")\n        result.append(token)\n    return \"\".join(result)\n\ndef generate_data(lines):\n    \"\"\"Generate tokens and labels for multiple lines.\"\"\"\n    inputs = []\n    labels = []\n    \n    for line in lines:\n        line = line.strip()\n        if not line:\n            continue\n            \n        language = model.predict([line])[0][0][0]\n        if language == \"__label__mya_Mymr\":\n            result = create_labels(line)\n            inputs.append(result[\"tokens\"])\n            labels.append(result[\"labels\"])\n    \n    return inputs, labels\n\ndef process_and_expand(examples):\n    \"\"\"\n    Input: batch of N contents\n    Output: batch of M rows (where M > N, since each content has multiple lines)\n    \"\"\"\n    all_tokens = []\n    all_labels = []\n    \n    for content in examples['content']:\n        lines = [line.strip() for line in re.split(r'\\n+', content) if line.strip()]\n        \n        if lines:\n            input_data, labels = generate_data(lines)\n            # input_data: [['tok1', 'tok2'], ['tok3', 'tok4', 'tok5'], ...]  <- 5 lines\n            # labels:     [['B', 'I'],       ['B', 'I', 'I'],          ...]  <- 5 lines\n            \n            # Each line becomes a new row\n            for tokens, label in zip(input_data, labels):\n                all_tokens.append(tokens)\n                all_labels.append(label)\n    \n    return {\n        \"tokens\": all_tokens,  # M items (expanded)\n        \"labels\": all_labels   # M items (expanded)\n    }\n","metadata":{"execution":{"iopub.status.busy":"2025-12-23T16:02:21.907635Z","iopub.execute_input":"2025-12-23T16:02:21.907951Z","iopub.status.idle":"2025-12-23T16:02:22.067205Z","shell.execute_reply.started":"2025-12-23T16:02:21.907899Z","shell.execute_reply":"2025-12-23T16:02:22.066307Z"},"trusted":true},"outputs":[],"execution_count":4},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Test cases\ntest_cases = [\n    \"နယူးဇီလန် ရဲများသည် (Black) Beauty1 45 and 678 ၏\",\n    \"နယူးဇီလန် ရဲများသည်(Black) Beauty ၏\",\n    \"နယူးဇီလန် ရဲများသည် Black Beauty (၏)\",\n    \"Hello World\",\n    \"မြန်မာ English mixed စာ\",\n    \"test123 hello\",\n    \"Beauty1 is 45kg\",\n    \"ပြည်ထောင်စုဝန်ကြီးဦးမောင်မောင်အုန်းကလည်းမြန်မာနိုင်ငံမှထွက်သွားသည့်\",\n    'ပြည်ထောင်စုဝန်ကြီးဦးမောင်မောင်အုန်းကလည်းမြန်မာနိုင်ငံ PTT IS မှထွက်သွားသည့်'\n]\n\nfor text in test_cases:\n    result = create_labels(text)\n    reconstructed = reconstruct(result[\"tokens\"], result[\"labels\"])\n    match = \"✅\" if text == reconstructed else \"❌\"\n    print(f\"Input:   {text}\")\n    print(f\"Tokens:  {result['tokens']}\")\n    print(f\"Labels:  {result['labels']}\")\n    print(f\"Output:  {reconstructed} {match}\")\n    print()","metadata":{"execution":{"iopub.status.busy":"2025-12-23T16:02:22.069205Z","iopub.execute_input":"2025-12-23T16:02:22.069943Z","iopub.status.idle":"2025-12-23T16:02:22.097265Z","shell.execute_reply.started":"2025-12-23T16:02:22.069885Z","shell.execute_reply":"2025-12-23T16:02:22.096211Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Input:   နယူးဇီလန် ရဲများသည် (Black) Beauty1 45 and 678 ၏\nTokens:  ['န', 'ယူး', 'ဇီ', 'လန်', 'ရဲ', 'များ', 'သည်', '(Black)', 'Beauty1', '45', 'and', '678', '၏']\nLabels:  ['B', 'I', 'I', 'I', 'B', 'I', 'I', 'B', 'B', 'B', 'B', 'B', 'B']\nOutput:  နယူးဇီလန် ရဲများသည် (Black) Beauty1 45 and 678 ၏ ✅\n\nInput:   နယူးဇီလန် ရဲများသည်(Black) Beauty ၏\nTokens:  ['န', 'ယူး', 'ဇီ', 'လန်', 'ရဲ', 'များ', 'သည်', '(Black)', 'Beauty', '၏']\nLabels:  ['B', 'I', 'I', 'I', 'B', 'I', 'I', 'I', 'B', 'B']\nOutput:  နယူးဇီလန် ရဲများသည်(Black) Beauty ၏ ✅\n\nInput:   နယူးဇီလန် ရဲများသည် Black Beauty (၏)\nTokens:  ['န', 'ယူး', 'ဇီ', 'လန်', 'ရဲ', 'များ', 'သည်', 'Black', ' Beauty', '(', '၏', ')']\nLabels:  ['B', 'I', 'I', 'I', 'B', 'I', 'I', 'B', 'B', 'B', 'I', 'I']\nOutput:  နယူးဇီလန် ရဲများသည် Black  Beauty (၏) ❌\n\nInput:   Hello World\nTokens:  ['Hello', ' World']\nLabels:  ['B', 'B']\nOutput:  Hello  World ❌\n\nInput:   မြန်မာ English mixed စာ\nTokens:  ['မြန်', 'မာ', 'English', ' mixed', 'စာ']\nLabels:  ['B', 'I', 'B', 'B', 'B']\nOutput:  မြန်မာ English  mixed စာ ❌\n\nInput:   test123 hello\nTokens:  ['test123', 'hello']\nLabels:  ['B', 'B']\nOutput:  test123 hello ✅\n\nInput:   Beauty1 is 45kg\nTokens:  ['Beauty1', 'is', '45kg']\nLabels:  ['B', 'B', 'B']\nOutput:  Beauty1 is 45kg ✅\n\nInput:   ပြည်ထောင်စုဝန်ကြီးဦးမောင်မောင်အုန်းကလည်းမြန်မာနိုင်ငံမှထွက်သွားသည့်\nTokens:  ['ပြည်', 'ထောင်', 'စု', 'ဝန်', 'ကြီး', 'ဦး', 'မောင်', 'မောင်', 'အုန်း', 'က', 'လည်း', 'မြန်', 'မာ', 'နိုင်', 'ငံ', 'မှ', 'ထွက်', 'သွား', 'သည့်']\nLabels:  ['B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I']\nOutput:  ပြည်ထောင်စုဝန်ကြီးဦးမောင်မောင်အုန်းကလည်းမြန်မာနိုင်ငံမှထွက်သွားသည့် ✅\n\nInput:   ပြည်ထောင်စုဝန်ကြီးဦးမောင်မောင်အုန်းကလည်းမြန်မာနိုင်ငံ PTT IS မှထွက်သွားသည့်\nTokens:  ['ပြည်', 'ထောင်', 'စု', 'ဝန်', 'ကြီး', 'ဦး', 'မောင်', 'မောင်', 'အုန်း', 'က', 'လည်း', 'မြန်', 'မာ', 'နိုင်', 'ငံ', 'PTT', ' IS', 'မှ', 'ထွက်', 'သွား', 'သည့်']\nLabels:  ['B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'B', 'B', 'I', 'I', 'I']\nOutput:  ပြည်ထောင်စုဝန်ကြီးဦးမောင်မောင်အုန်းကလည်းမြန်မာနိုင်ငံ PTT  IS မှထွက်သွားသည့် ❌\n\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"content = ds['train'][0]['content']\n\nlines = [line.strip() for line in re.split(r'\\n+', content) if line.strip()]\n\ngenerate_data(lines)","metadata":{"execution":{"iopub.status.busy":"2025-12-23T16:02:27.518447Z","iopub.execute_input":"2025-12-23T16:02:27.518789Z","iopub.status.idle":"2025-12-23T16:02:27.527597Z","shell.execute_reply.started":"2025-12-23T16:02:27.518758Z","shell.execute_reply":"2025-12-23T16:02:27.526540Z"},"trusted":true},"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"([['(', 'ဒု', ')', 'ချီး', 'ယား', 'တန်း', '(', 'တောင်', ')', 'ရွာ'],\n  ['ကိုး', 'ကား']],\n [['B', 'I', 'I', 'B', 'I', 'I', 'B', 'I', 'I', 'I'], ['B', 'I']])"},"metadata":{}}],"execution_count":7},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Create the Segmentation Dataset","metadata":{}},{"cell_type":"code","source":"# This expands the dataset!\nnew_ds = ds['train'].map(\n    process_and_expand,\n    batched=True,\n    remove_columns=ds['train'].column_names,\n)\n\nprint(f\"Original rows: {len(ds['train'])}\")\nprint(f\"New rows: {len(new_ds)}\")","metadata":{"execution":{"iopub.status.busy":"2025-12-23T16:02:31.813030Z","iopub.execute_input":"2025-12-23T16:02:31.813407Z","iopub.status.idle":"2025-12-23T16:07:12.730689Z","shell.execute_reply.started":"2025-12-23T16:02:31.813374Z","shell.execute_reply":"2025-12-23T16:07:12.729682Z"},"trusted":true},"outputs":[{"name":"stderr","text":"Parameter 'function'=<function process_and_expand at 0x7c0da728dee0> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only shown once. Subsequent hashing failures won't be shown.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/116340 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"90c7f2ae7287437496f21f3b9d046424"}},"metadata":{}},{"name":"stdout","text":"Original rows: 116340\nNew rows: 753639\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"label_names = [\"B\", \"I\"]\nlabel2id = {label: i for i, label in enumerate(label_names)}","metadata":{"execution":{"iopub.status.busy":"2025-12-23T16:07:12.732752Z","iopub.execute_input":"2025-12-23T16:07:12.733108Z","iopub.status.idle":"2025-12-23T16:07:12.738214Z","shell.execute_reply.started":"2025-12-23T16:07:12.733078Z","shell.execute_reply":"2025-12-23T16:07:12.737180Z"},"trusted":true},"outputs":[],"execution_count":9},{"cell_type":"code","source":"features = Features({\n    \"tokens\": Sequence(Value(\"string\")),\n    \"segment_tags\": Sequence(ClassLabel(names=label_names)),\n})","metadata":{"execution":{"iopub.status.busy":"2025-12-23T16:07:12.739381Z","iopub.execute_input":"2025-12-23T16:07:12.739724Z","iopub.status.idle":"2025-12-23T16:07:12.782820Z","shell.execute_reply.started":"2025-12-23T16:07:12.739692Z","shell.execute_reply":"2025-12-23T16:07:12.781853Z"},"trusted":true},"outputs":[],"execution_count":10},{"cell_type":"code","source":"def convert_labels_to_ids(example):\n    example[\"segment_tags\"] = [label2id[label] for label in example[\"labels\"]]\n    return example","metadata":{"execution":{"iopub.status.busy":"2025-12-23T16:07:12.784899Z","iopub.execute_input":"2025-12-23T16:07:12.785833Z","iopub.status.idle":"2025-12-23T16:07:12.800378Z","shell.execute_reply.started":"2025-12-23T16:07:12.785800Z","shell.execute_reply":"2025-12-23T16:07:12.799399Z"},"trusted":true},"outputs":[],"execution_count":11},{"cell_type":"code","source":"new_ds = new_ds.map(convert_labels_to_ids, remove_columns=[\"labels\"])","metadata":{"execution":{"iopub.status.busy":"2025-12-23T16:07:12.801375Z","iopub.execute_input":"2025-12-23T16:07:12.801646Z","iopub.status.idle":"2025-12-23T16:08:26.768736Z","shell.execute_reply.started":"2025-12-23T16:07:12.801620Z","shell.execute_reply":"2025-12-23T16:08:26.767515Z"},"trusted":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/753639 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6eb00a3b25b549d9a9aaaf943ffd0d4a"}},"metadata":{}}],"execution_count":12},{"cell_type":"markdown","source":"# Remove Duplications","metadata":{}},{"cell_type":"code","source":"df = new_ds.to_pandas()\n\n# Convert list to string for deduplication\ndf['tokens_str'] = df['tokens'].apply(lambda x: '|'.join(x))\ndf = df.drop_duplicates(subset='tokens_str')\ndf = df.drop(columns='tokens_str')\n\n# Simple split\ntrain_df, test_df = train_test_split(df, test_size=0.05, random_state=42)\n\nprint(f\"Train: {len(train_df)}\")\nprint(f\"Test: {len(test_df)}\")","metadata":{"execution":{"iopub.status.busy":"2025-12-23T16:08:26.770612Z","iopub.execute_input":"2025-12-23T16:08:26.770963Z","iopub.status.idle":"2025-12-23T16:08:32.987836Z","shell.execute_reply.started":"2025-12-23T16:08:26.770926Z","shell.execute_reply":"2025-12-23T16:08:32.987025Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Train: 544133\nTest: 28639\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"# Convert back to dataset\ndeduped_ds = DatasetDict({\n    \"train\": Dataset.from_pandas(train_df, preserve_index=False),\n    \"test\": Dataset.from_pandas(test_df, preserve_index=False),\n})","metadata":{"execution":{"iopub.status.busy":"2025-12-23T16:08:32.989209Z","iopub.execute_input":"2025-12-23T16:08:32.989512Z","iopub.status.idle":"2025-12-23T16:08:42.003373Z","shell.execute_reply.started":"2025-12-23T16:08:32.989476Z","shell.execute_reply":"2025-12-23T16:08:42.002393Z"},"trusted":true},"outputs":[],"execution_count":14},{"cell_type":"code","source":"deduped_ds = deduped_ds.cast(features)","metadata":{"execution":{"iopub.status.busy":"2025-12-23T16:08:42.004495Z","iopub.execute_input":"2025-12-23T16:08:42.004814Z","iopub.status.idle":"2025-12-23T16:08:43.669083Z","shell.execute_reply.started":"2025-12-23T16:08:42.004786Z","shell.execute_reply":"2025-12-23T16:08:43.668073Z"},"trusted":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"Casting the dataset:   0%|          | 0/544133 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"08ad890cc3494c158bbcb19886e3e54b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Casting the dataset:   0%|          | 0/28639 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c6a79ba2fe7c4a199b511e7900987006"}},"metadata":{}}],"execution_count":15},{"cell_type":"markdown","source":"# Upload to HuggingFace","metadata":{}},{"cell_type":"code","source":"deduped_ds.push_to_hub(\"chuuhtetnaing/myanmar-text-segmentation-dataset\", private=True, commit_message=\"add space in english word if previous word is english word\")","metadata":{"execution":{"iopub.status.busy":"2025-12-23T16:09:46.103035Z","iopub.execute_input":"2025-12-23T16:09:46.105213Z","iopub.status.idle":"2025-12-23T16:10:02.700590Z","shell.execute_reply.started":"2025-12-23T16:09:46.105160Z","shell.execute_reply":"2025-12-23T16:10:02.699585Z"},"trusted":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"Uploading the dataset shards:   0%|          | 0/2 [00:00<?, ? shards/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"45215f9362014264a4b4f085d855bf76"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Creating parquet from Arrow format:   0%|          | 0/4 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"57f16a2aabd741ab89003c232289d91e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Processing Files (0 / 0): |          |  0.00B /  0.00B            ","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"60c108f34c2949af8a98dfc6ab3fe9f1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"New Data Upload: |          |  0.00B /  0.00B            ","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0621f09283f3409390722de91bc953ed"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Creating parquet from Arrow format:   0%|          | 0/4 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e92926a6b568409f98f53ba271750be9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Processing Files (0 / 0): |          |  0.00B /  0.00B            ","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0c2efb3a34674d98b388eddcdd849a58"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"New Data Upload: |          |  0.00B /  0.00B            ","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c8b0f248ff0c4bb682e4675ffb5ead60"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ? shards/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a48689b96b9d4db5bce026729432de34"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1d2782b4db954fa19474ab4235f1b1ed"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Processing Files (0 / 0): |          |  0.00B /  0.00B            ","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2946a1350df44681aa3c92261175e921"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"New Data Upload: |          |  0.00B /  0.00B            ","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"00dce70656db465d8520ef18bd913a90"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"README.md: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fa3ca7343a014140b38ccce6d8cc2905"}},"metadata":{}},{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"CommitInfo(commit_url='https://huggingface.co/datasets/chuuhtetnaing/myanmar-text-segmentation-dataset/commit/dab2cd081c4c98fb410308c3ea17b18cab395d9f', commit_message='add space in english word if previous word is english word', commit_description='', oid='dab2cd081c4c98fb410308c3ea17b18cab395d9f', pr_url=None, repo_url=RepoUrl('https://huggingface.co/datasets/chuuhtetnaing/myanmar-text-segmentation-dataset', endpoint='https://huggingface.co', repo_type='dataset', repo_id='chuuhtetnaing/myanmar-text-segmentation-dataset'), pr_revision=None, pr_num=None)"},"metadata":{}}],"execution_count":16},{"cell_type":"markdown","source":"# Example Reconstruction Function","metadata":{}},{"cell_type":"code","source":"def reconstruct(tokens, labels):\n    \"\"\"\n    Combine tokens based on B/I labels.\n    Add space before 'B' tokens (except the first one).\n    \"\"\"\n    result = []\n    for token, label in zip(tokens, labels):\n        if label == 0 and result:\n            result.append(\" \")\n        result.append(token.strip())\n    return \"\".join(result)","metadata":{"execution":{"iopub.status.busy":"2025-12-23T16:13:18.692960Z","iopub.execute_input":"2025-12-23T16:13:18.693315Z","iopub.status.idle":"2025-12-23T16:13:18.698770Z","shell.execute_reply.started":"2025-12-23T16:13:18.693277Z","shell.execute_reply":"2025-12-23T16:13:18.697799Z"},"trusted":true},"outputs":[],"execution_count":28},{"cell_type":"code","source":"reconstruct(new_ds[821]['tokens'], new_ds[821]['segment_tags'])","metadata":{"execution":{"iopub.status.busy":"2025-12-23T16:13:19.248746Z","iopub.execute_input":"2025-12-23T16:13:19.249123Z","iopub.status.idle":"2025-12-23T16:13:19.257193Z","shell.execute_reply.started":"2025-12-23T16:13:19.249089Z","shell.execute_reply":"2025-12-23T16:13:19.256273Z"},"trusted":true},"outputs":[{"execution_count":29,"output_type":"execute_result","data":{"text/plain":"'alternative metal တီးဝိုင်းများဖြစ်သည့် Fishbone, Faith No Moreနှင့် Red Hot Chilli Peppers တို့သည် heavy metal နှင့် funk ကို ရောနှောပြီး alt-metal ၏ မျိုးခွဲဖြစ်သည့် funk metal ကို ဖန်တီးခဲ့သည်။ ဤအမျိုးအစားထဲမှ အစောပိုင်းတီးဝိုင်းများသည် hardcore punk မှ ဆင်းသက်လာခဲ့သည်။ Faith No More, Jane’s Addiction နှင့် Soundgarden တို့သည် အစောဆုံး alternative metal ဖျော်ဖြေတင်ဆက်မှုဟု အသိအမှတ်ပြုခဲ့သည်။ ထိုတီးဝိုင်းသုံးခုစလုံးသည် တစ်ချိန်တည်းတွင် ပေါ်ထွက်လာခဲ့ပုံပေါ်ပြီး ၈၀နောက်ပိုင်းအထိ heavy metal ဂီတနှင့် ကွဲပြားသော အမျိုးအစားများစွာတို့ကို ဤအမျိုးအတွက် ရောနှောပြီး template များစီစဉ်ခဲ့သည်။ ၁၉၈၀ ခုနှစ်များမှ စတင်၍ alt-metal တီးဝိုင်းများသည် American independent rock အဖြစ်အပျက်သို့အမြစ်တွယ်ခဲ့သည်။ ၁၉၉၀ အစောပိုင်းတွင် hard rock ၏ ပုံစံတစ်မျိုးဖြစ်သော grunge ပေါ်ထွက်လာပြီး alternative metal ကို mainstream ပရိသတ်များကို လက်ခံစေရန် ကူညီစေခဲ့သည်။ တီးဝိုင်းအချို့သည် အမျိုးအစားနှင့် ပတ်သက်၍ သူတို့၏ အဆင့်အတန်းကို metal တီးဝိုင်းဟု သတ်မှတ်ရန် ငြင်းဆိုခဲ့သည်။'"},"metadata":{}}],"execution_count":29},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}