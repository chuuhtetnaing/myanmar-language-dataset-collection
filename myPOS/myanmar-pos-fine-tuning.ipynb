{
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3 (ipykernel)",
   "language": "python"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.12",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [],
   "dockerImageVersionId": 31236,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook",
   "isGpuEnabled": true
  },
  "colab": {
   "provenance": [],
   "gpuType": "A100"
  },
  "accelerator": "GPU"
 },
 "nbformat_minor": 0,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "!pip install evaluate seqeval -qqq"
   ],
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-12-22T17:04:02.998469Z",
     "iopub.execute_input": "2025-12-22T17:04:02.998752Z",
     "iopub.status.idle": "2025-12-22T17:04:13.023554Z",
     "shell.execute_reply.started": "2025-12-22T17:04:02.998718Z",
     "shell.execute_reply": "2025-12-22T17:04:13.022820Z"
    },
    "id": "NitWTejZkGOj"
   },
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "source": [
    "from huggingface_hub import login\n",
    "import wandb\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import DataCollatorForTokenClassification\n",
    "import evaluate\n",
    "from transformers import AutoModelForTokenClassification, TrainingArguments, Trainer\n",
    "import numpy as np\n",
    "\n",
    "wandb.login(key=\"\")\n",
    "login(token=\"\")\n",
    "ds = load_dataset(\"chuuhtetnaing/myanmar-pos-dataset\")\n",
    "\n",
    "seqeval = evaluate.load(\"seqeval\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"chuuhtetnaing/myanmar-text-segmentation-model\")\n",
    "data_collator = DataCollatorForTokenClassification(tokenizer=tokenizer)"
   ],
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-12-22T17:04:42.576838Z",
     "iopub.execute_input": "2025-12-22T17:04:42.577181Z",
     "iopub.status.idle": "2025-12-22T17:06:05.399167Z",
     "shell.execute_reply.started": "2025-12-22T17:04:42.577148Z",
     "shell.execute_reply": "2025-12-22T17:06:05.398547Z"
    },
    "id": "Pl5umVHbkGOk",
    "outputId": "25171ea8-7cea-4ad3-adf7-d59bd4f0ed3e",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: \u001B[33mWARNING\u001B[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \u001B[33mWARNING\u001B[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Currently logged in as: \u001B[33mchuu\u001B[0m to \u001B[32mhttps://api.wandb.ai\u001B[0m. Use \u001B[1m`wandb login --relogin`\u001B[0m to force relogin\n",
      "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "source": [
    "id2label = {i: l for i, l in enumerate(ds['train'].features['pos_tags'].feature.names)}\n",
    "label2id = {l: i for i, l in enumerate(ds['train'].features['pos_tags'].feature.names)}"
   ],
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-12-22T17:06:05.400406Z",
     "iopub.execute_input": "2025-12-22T17:06:05.401118Z",
     "iopub.status.idle": "2025-12-22T17:06:05.406101Z",
     "shell.execute_reply.started": "2025-12-22T17:06:05.401088Z",
     "shell.execute_reply": "2025-12-22T17:06:05.405488Z"
    },
    "id": "4Ese_AHzkGOl"
   },
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "source": [
    "id2label"
   ],
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-12-22T17:06:16.019361Z",
     "iopub.execute_input": "2025-12-22T17:06:16.019950Z",
     "iopub.status.idle": "2025-12-22T17:06:16.024546Z",
     "shell.execute_reply.started": "2025-12-22T17:06:16.019922Z",
     "shell.execute_reply": "2025-12-22T17:06:16.023815Z"
    },
    "id": "GWi0H52AkGOl",
    "outputId": "a3b022f8-c214-4924-97df-cef45ede38c9",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{0: 'B-abb',\n",
       " 1: 'B-adj',\n",
       " 2: 'B-adv',\n",
       " 3: 'B-conj',\n",
       " 4: 'B-fw',\n",
       " 5: 'B-int',\n",
       " 6: 'B-n',\n",
       " 7: 'B-num',\n",
       " 8: 'B-part',\n",
       " 9: 'B-ppm',\n",
       " 10: 'B-pron',\n",
       " 11: 'B-punc',\n",
       " 12: 'B-sb',\n",
       " 13: 'B-tn',\n",
       " 14: 'B-v',\n",
       " 15: 'I-abb',\n",
       " 16: 'I-adj',\n",
       " 17: 'I-adv',\n",
       " 18: 'I-conj',\n",
       " 19: 'I-fw',\n",
       " 20: 'I-int',\n",
       " 21: 'I-n',\n",
       " 22: 'I-num',\n",
       " 23: 'I-part',\n",
       " 24: 'I-ppm',\n",
       " 25: 'I-pron',\n",
       " 26: 'I-punc',\n",
       " 27: 'I-tn',\n",
       " 28: 'I-v'}"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "source": [
    "label2id"
   ],
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-12-22T17:06:16.970392Z",
     "iopub.execute_input": "2025-12-22T17:06:16.971250Z",
     "iopub.status.idle": "2025-12-22T17:06:16.975979Z",
     "shell.execute_reply.started": "2025-12-22T17:06:16.971215Z",
     "shell.execute_reply": "2025-12-22T17:06:16.975225Z"
    },
    "id": "ZHv0CsivkGOl",
    "outputId": "9ffc967d-b9f8-4278-c484-c57a5e65812c",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'B-abb': 0,\n",
       " 'B-adj': 1,\n",
       " 'B-adv': 2,\n",
       " 'B-conj': 3,\n",
       " 'B-fw': 4,\n",
       " 'B-int': 5,\n",
       " 'B-n': 6,\n",
       " 'B-num': 7,\n",
       " 'B-part': 8,\n",
       " 'B-ppm': 9,\n",
       " 'B-pron': 10,\n",
       " 'B-punc': 11,\n",
       " 'B-sb': 12,\n",
       " 'B-tn': 13,\n",
       " 'B-v': 14,\n",
       " 'I-abb': 15,\n",
       " 'I-adj': 16,\n",
       " 'I-adv': 17,\n",
       " 'I-conj': 18,\n",
       " 'I-fw': 19,\n",
       " 'I-int': 20,\n",
       " 'I-n': 21,\n",
       " 'I-num': 22,\n",
       " 'I-part': 23,\n",
       " 'I-ppm': 24,\n",
       " 'I-pron': 25,\n",
       " 'I-punc': 26,\n",
       " 'I-tn': 27,\n",
       " 'I-v': 28}"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "source": [
    "num_labels = len(ds['train'].features['pos_tags'].feature.names)\n",
    "num_labels"
   ],
   "metadata": {
    "id": "AEiN5yNo3M3M",
    "trusted": true,
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "eeaccafd-1816-40b5-ffae-b1d7ac955572"
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "29"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "source": [
    "model = AutoModelForTokenClassification.from_pretrained(\n",
    "    \"chuuhtetnaing/myanmar-text-segmentation-model\", num_labels=num_labels, id2label=id2label, label2id=label2id, ignore_mismatched_sizes=True\n",
    ")"
   ],
   "metadata": {
    "id": "OWbI37A2mrdV",
    "outputId": "6593d46e-6546-4991-a896-7c3342d21574",
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-12-22T17:06:19.753924Z",
     "iopub.execute_input": "2025-12-22T17:06:19.754566Z",
     "iopub.status.idle": "2025-12-22T17:06:30.897608Z",
     "shell.execute_reply.started": "2025-12-22T17:06:19.754538Z",
     "shell.execute_reply": "2025-12-22T17:06:30.896757Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at chuuhtetnaing/myanmar-text-segmentation-model and are newly initialized because the shapes did not match:\n",
      "- classifier.bias: found shape torch.Size([2]) in the checkpoint and torch.Size([29]) in the model instantiated\n",
      "- classifier.weight: found shape torch.Size([2, 768]) in the checkpoint and torch.Size([29, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "source": [
    "label_list = ds[\"train\"].features[f\"pos_tags\"].feature.names\n",
    "\n",
    "def compute_metrics(p):\n",
    "    predictions, labels = p\n",
    "    predictions = np.argmax(predictions, axis=2)\n",
    "\n",
    "    true_predictions = [\n",
    "        [label_list[p] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "    true_labels = [\n",
    "        [label_list[l] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "\n",
    "    results = seqeval.compute(predictions=true_predictions, references=true_labels)\n",
    "    return {\n",
    "        \"precision\": results[\"overall_precision\"],\n",
    "        \"recall\": results[\"overall_recall\"],\n",
    "        \"f1\": results[\"overall_f1\"],\n",
    "        \"accuracy\": results[\"overall_accuracy\"],\n",
    "    }"
   ],
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-12-22T17:06:31.797744Z",
     "iopub.execute_input": "2025-12-22T17:06:31.798226Z",
     "iopub.status.idle": "2025-12-22T17:06:31.803989Z",
     "shell.execute_reply.started": "2025-12-22T17:06:31.798195Z",
     "shell.execute_reply": "2025-12-22T17:06:31.803359Z"
    },
    "id": "sY7S2nMYkGOl"
   },
   "outputs": [],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "source": [
    "def tokenize_and_align_labels(examples):\n",
    "    tokenized_inputs = tokenizer(examples[\"tokens\"], truncation=True, is_split_into_words=True)\n",
    "\n",
    "    labels = []\n",
    "    for i, label in enumerate(examples[f\"pos_tags\"]):\n",
    "        word_ids = tokenized_inputs.word_ids(batch_index=i)  # Map tokens to their respective word.\n",
    "        previous_word_idx = None\n",
    "        label_ids = []\n",
    "        for word_idx in word_ids:  # Set the special tokens to -100.\n",
    "            if word_idx is None:\n",
    "                label_ids.append(-100)\n",
    "            elif word_idx != previous_word_idx:  # Only label the first token of a given word.\n",
    "                label_ids.append(label[word_idx])\n",
    "            else:\n",
    "                label_ids.append(-100)\n",
    "            previous_word_idx = word_idx\n",
    "        labels.append(label_ids)\n",
    "\n",
    "    tokenized_inputs[\"labels\"] = labels\n",
    "    return tokenized_inputs"
   ],
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-12-22T17:06:33.116662Z",
     "iopub.execute_input": "2025-12-22T17:06:33.117079Z",
     "iopub.status.idle": "2025-12-22T17:06:34.248874Z",
     "shell.execute_reply.started": "2025-12-22T17:06:33.117051Z",
     "shell.execute_reply": "2025-12-22T17:06:34.248144Z"
    },
    "id": "0TS927oqkGOl"
   },
   "outputs": [],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "source": [
    "tokenized_ds = ds.map(tokenize_and_align_labels, batched=True)"
   ],
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-12-22T17:06:34.292575Z",
     "iopub.execute_input": "2025-12-22T17:06:34.293119Z",
     "iopub.status.idle": "2025-12-22T17:10:08.570121Z",
     "shell.execute_reply.started": "2025-12-22T17:06:34.293094Z",
     "shell.execute_reply": "2025-12-22T17:10:08.569309Z"
    },
    "id": "0S7QFdFgkGOl"
   },
   "outputs": [],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "source": [
    "tokenized_ds"
   ],
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-12-22T17:10:08.571647Z",
     "iopub.execute_input": "2025-12-22T17:10:08.571977Z",
     "iopub.status.idle": "2025-12-22T17:10:08.576959Z",
     "shell.execute_reply.started": "2025-12-22T17:10:08.571954Z",
     "shell.execute_reply": "2025-12-22T17:10:08.576089Z"
    },
    "id": "3-oYzCP8kGOm",
    "outputId": "b8540312-551b-4de7-a1bd-5af98ba64c0e",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['tokens', 'pos_tags', 'input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 32777\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['tokens', 'pos_tags', 'input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 8195\n",
       "    })\n",
       "})"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "trusted": true,
    "id": "G08txQLikGOm"
   },
   "outputs": [],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"myanmar_pos_model\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=64,\n",
    "    per_device_eval_batch_size=64,\n",
    "    num_train_epochs=10,\n",
    "    weight_decay=0.01,\n",
    "    eval_strategy=\"epoch\", #\"steps\",\n",
    "    save_strategy=\"epoch\", #\"steps\",\n",
    "    load_best_model_at_end=True,\n",
    "    push_to_hub=True,\n",
    "    hub_private_repo=True,\n",
    "    # eval_steps=1000,\n",
    "    # save_steps=1000,\n",
    "    logging_steps=10,\n",
    "    logging_strategy=\"steps\",\n",
    "    # save_total_limit=2,\n",
    "    # hub_strategy=\"all_checkpoints\",\n",
    "    save_safetensors=True,\n",
    "    metric_for_best_model=\"f1\",\n",
    "    greater_is_better=True,\n",
    "    report_to=[\"wandb\", \"tensorboard\"],\n",
    "    gradient_accumulation_steps=8,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_ds[\"train\"],\n",
    "    eval_dataset=tokenized_ds[\"test\"],\n",
    "    processing_class=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ],
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-12-22T17:10:18.049977Z",
     "iopub.execute_input": "2025-12-22T17:10:18.050303Z",
     "iopub.status.idle": "2025-12-22T17:10:18.746625Z",
     "shell.execute_reply.started": "2025-12-22T17:10:18.050262Z",
     "shell.execute_reply": "2025-12-22T17:10:18.746030Z"
    },
    "id": "ZiOW7tQpkGOm"
   },
   "outputs": [],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "source": [
    "wandb.init(project=\"myanmar-pos-fine-tuning\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 120
    },
    "id": "_Rkb3Bhd6Cfn",
    "outputId": "c714f45f-16a0-42ce-b3b3-1b997b7ae8e5"
   },
   "execution_count": 13,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": []
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Tracking run with wandb version 0.23.1"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Run data is saved locally in <code>/content/wandb/run-20251224_153738-lk04zg14</code>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/chuu/myanmar-pos-fine-tuning/runs/lk04zg14' target=\"_blank\">eager-durian-7</a></strong> to <a href='https://wandb.ai/chuu/myanmar-pos-fine-tuning' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View project at <a href='https://wandb.ai/chuu/myanmar-pos-fine-tuning' target=\"_blank\">https://wandb.ai/chuu/myanmar-pos-fine-tuning</a>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run at <a href='https://wandb.ai/chuu/myanmar-pos-fine-tuning/runs/lk04zg14' target=\"_blank\">https://wandb.ai/chuu/myanmar-pos-fine-tuning/runs/lk04zg14</a>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/chuu/myanmar-pos-fine-tuning/runs/lk04zg14?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7960203fb290>"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "trainer.train()"
   ],
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-12-22T17:17:28.882831Z",
     "iopub.execute_input": "2025-12-22T17:17:28.883185Z",
     "iopub.status.idle": "2025-12-22T17:17:56.932984Z",
     "shell.execute_reply.started": "2025-12-22T17:17:28.883158Z",
     "shell.execute_reply": "2025-12-22T17:17:56.931892Z"
    },
    "id": "u_Z7TdYykGOm",
    "outputId": "e47b4266-2c38-4f7a-c090-60ba6e26c2e3",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 660
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='650' max='650' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [650/650 32:05, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.761100</td>\n",
       "      <td>0.541684</td>\n",
       "      <td>0.799976</td>\n",
       "      <td>0.842209</td>\n",
       "      <td>0.820549</td>\n",
       "      <td>0.855660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.373600</td>\n",
       "      <td>0.317003</td>\n",
       "      <td>0.887862</td>\n",
       "      <td>0.904016</td>\n",
       "      <td>0.895866</td>\n",
       "      <td>0.912292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.301500</td>\n",
       "      <td>0.276361</td>\n",
       "      <td>0.899971</td>\n",
       "      <td>0.914323</td>\n",
       "      <td>0.907090</td>\n",
       "      <td>0.921923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.258900</td>\n",
       "      <td>0.256176</td>\n",
       "      <td>0.906666</td>\n",
       "      <td>0.918871</td>\n",
       "      <td>0.912728</td>\n",
       "      <td>0.926480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.250400</td>\n",
       "      <td>0.247340</td>\n",
       "      <td>0.910443</td>\n",
       "      <td>0.921897</td>\n",
       "      <td>0.916134</td>\n",
       "      <td>0.928460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.220900</td>\n",
       "      <td>0.240286</td>\n",
       "      <td>0.914146</td>\n",
       "      <td>0.923686</td>\n",
       "      <td>0.918891</td>\n",
       "      <td>0.931057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.225300</td>\n",
       "      <td>0.234137</td>\n",
       "      <td>0.916762</td>\n",
       "      <td>0.925648</td>\n",
       "      <td>0.921184</td>\n",
       "      <td>0.932788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.236100</td>\n",
       "      <td>0.231913</td>\n",
       "      <td>0.918273</td>\n",
       "      <td>0.926382</td>\n",
       "      <td>0.922309</td>\n",
       "      <td>0.933686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.214000</td>\n",
       "      <td>0.230518</td>\n",
       "      <td>0.918021</td>\n",
       "      <td>0.926776</td>\n",
       "      <td>0.922378</td>\n",
       "      <td>0.933610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.219900</td>\n",
       "      <td>0.231061</td>\n",
       "      <td>0.918407</td>\n",
       "      <td>0.926501</td>\n",
       "      <td>0.922436</td>\n",
       "      <td>0.933680</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.12/dist-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.12/dist-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.12/dist-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.12/dist-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.12/dist-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "TrainOutput(global_step=650, training_loss=0.39428256841806264, metrics={'train_runtime': 1927.8091, 'train_samples_per_second': 170.022, 'train_steps_per_second': 0.337, 'total_flos': 2.392540791016854e+16, 'train_loss': 0.39428256841806264, 'epoch': 10.0})"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "tt1ZyGRDJT7v"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {
    "id": "eOunImoJJcPn"
   },
   "cell_type": "markdown",
   "source": "# Add the training and evaluation result manually"
  },
  {
   "cell_type": "code",
   "source": [
    "# import json\n",
    "# from huggingface_hub import HfApi\n",
    "#\n",
    "# # Get log history directly from trainer\n",
    "# log_history = trainer.state.log_history\n",
    "#\n",
    "# def fmt(val):\n",
    "#     \"\"\"Format value, handle None\"\"\"\n",
    "#     return f\"{val:.4f}\" if val is not None else \"N/A\"\n",
    "#\n",
    "# # Get eval logs with epoch info\n",
    "# eval_logs = [log for log in log_history if \"eval_loss\" in log]\n",
    "# train_logs = {log[\"step\"]: log for log in log_history if \"loss\" in log and \"eval_loss\" not in log}\n",
    "#\n",
    "# table_rows = []\n",
    "# table_rows.append(\"| Epoch | Training Loss | Validation Loss | Precision | Recall | F1 | Accuracy |\")\n",
    "# table_rows.append(\"|-------|---------------|-----------------|-----------|--------|------|----------|\")\n",
    "#\n",
    "# for e in eval_logs:\n",
    "#     epoch = e.get(\"epoch\")\n",
    "#     step = e.get(\"step\")\n",
    "#\n",
    "#     # Find closest training loss\n",
    "#     t = train_logs.get(step, {}).get(\"loss\") or next(\n",
    "#         (train_logs[s][\"loss\"] for s in range(step, step-1000, -100) if s in train_logs),\n",
    "#         None\n",
    "#     )\n",
    "#\n",
    "#     table_rows.append(\n",
    "#         f\"| {epoch:.0f} | {fmt(t)} | {fmt(e.get('eval_loss'))} | {fmt(e.get('eval_precision'))} | {fmt(e.get('eval_recall'))} | {fmt(e.get('eval_f1'))} | {fmt(e.get('eval_accuracy'))} |\"\n",
    "#     )\n",
    "#\n",
    "# readme = f\"\"\"---\n",
    "# license: apache-2.0\n",
    "# base_model: chuuhtetnaing/myanmar-text-segmentation-model\n",
    "# tags:\n",
    "#   - token-classification\n",
    "#   - myanmar\n",
    "#   - pos-tagging\n",
    "# language:\n",
    "#   - my\n",
    "# datasets:\n",
    "#   - chuuhtetnaing/myanmar-pos-dataset\n",
    "# metrics:\n",
    "#   - f1\n",
    "# ---\n",
    "#\n",
    "# # Myanmar POS Tagging Model\n",
    "#\n",
    "# Fine-tuned [myanmar-text-segmentation-model](https://huggingface.co/chuuhtetnaing/myanmar-text-segmentation-model) for Myanmar Part-of-Speech tagging.\n",
    "#\n",
    "# ## Training Results\n",
    "#\n",
    "# {chr(10).join(table_rows)}\n",
    "#\n",
    "# ## Training Details\n",
    "#\n",
    "# | Parameter | Value |\n",
    "# |-----------|-------|\n",
    "# | Base Model | chuuhtetnaing/myanmar-text-segmentation-model |\n",
    "# | Total Epochs | {trainer.state.epoch:.0f} |\n",
    "# | Total Steps | {trainer.state.global_step} |\n",
    "# | Best F1 | {fmt(trainer.state.best_metric)} |\n",
    "#\n",
    "# ## Usage\n",
    "# ```python\n",
    "# from transformers import pipeline\n",
    "#\n",
    "# nlp = pipeline(\"token-classification\", model=\"chuuhtetnaing/myanmar_pos_model\", aggregation_strategy=\"simple\")\n",
    "# result = nlp(\"သူသည်ကျောင်းသို့သွားသည်။\")\n",
    "# ```\n",
    "#\n",
    "# ## Labels\n",
    "#\n",
    "# | Tag | Description |\n",
    "# |-----|-------------|\n",
    "# | n | Noun |\n",
    "# | v | Verb |\n",
    "# | adj | Adjective |\n",
    "# | adv | Adverb |\n",
    "# | pron | Pronoun |\n",
    "# | num | Number |\n",
    "# | punc | Punctuation |\n",
    "# | part | Particle |\n",
    "# | conj | Conjunction |\n",
    "# | ppm | Postpositional Marker |\n",
    "# | fw | Foreign Word |\n",
    "# | abb | Abbreviation |\n",
    "# | int | Interjection |\n",
    "# | sb | Symbol |\n",
    "# | tn | Text Number |\n",
    "# \"\"\"\n",
    "#\n",
    "# # Upload README\n",
    "# api = HfApi()\n",
    "# api.upload_file(\n",
    "#     path_or_fileobj=readme.encode(),\n",
    "#     path_in_repo=\"README.md\",\n",
    "#     repo_id=\"chuuhtetnaing/myanmar_pos_model\",\n",
    "#     commit_message=\"Add training results\"\n",
    "# )\n",
    "# print(\"✅ Done!\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "o2Au67ICJcNJ",
    "outputId": "1f63cff6-22ce-434d-8ab5-6ede7062414e",
    "ExecuteTime": {
     "end_time": "2025-12-24T16:26:08.098524Z",
     "start_time": "2025-12-24T16:26:08.092344Z"
    }
   },
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "BEF40nowJcHY"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "ZsmApwHEJcAn"
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}
